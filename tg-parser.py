import aiohttp
import asyncio
import json
import os
import time
import random
import re
import urllib.parse as urllib_parse
from bs4 import BeautifulSoup
from datetime import datetime, timedelta, timezone
import logging
import tempfile
import shutil
from typing import Dict, List, Set, Optional

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
# --- –ö–æ–Ω–µ—Ü –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---

# –û—Ç–∫–ª—é—á–∞–µ–º warnings –¥–ª—è InsecureRequestWarning (—Ç–∞–∫ –∫–∞–∫ verify=False)
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã ---
MAX_THREADS_PARSING = 100
REQUEST_TIMEOUT_AIOHTTP = 30
MIN_PROFILES_TO_DOWNLOAD = 1
MAX_PROFILES_TO_DOWNLOAD = 9000
ALLOWED_PROTOCOLS = {"vless", "hy2", "tuic", "trojan"}
PROFILE_SCORE_WEIGHTS = {
    "security": 2,
    "sni": 2,
    "alpn": 2,
    "flow": 2,
    "headerType": 1,
    "path": 1,
    "obfs": 1,
    "mport": 1,
}
MAX_FAILED_CHECKS = 4  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –ø–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º –∫–∞–Ω–∞–ª–∞
FAILURE_HISTORY_FILE = 'channel_failure_history.json'  # –§–∞–π–ª –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –Ω–µ—É–¥–∞—á
NO_MORE_PAGES_HISTORY_FILE = 'no_more_pages_history.json'  # –§–∞–π–ª –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ "–ë–æ–ª—å—à–µ —Å—Ç—Ä–∞–Ω–∏—Ü –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
MAX_NO_MORE_PAGES_COUNT = 4  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ "–ë–æ–ª—å—à–µ —Å—Ç—Ä–∞–Ω–∏—Ü –Ω–µ –Ω–∞–π–¥–µ–Ω–æ" –ø–æ–¥—Ä—è–¥ –ø–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º –∫–∞–Ω–∞–ª–∞
PROFILE_FRESHNESS_DAYS = 3  # –ü–µ—Ä–∏–æ–¥ —Å–≤–µ–∂–µ—Å—Ç–∏ –ø—Ä–æ—Ñ–∏–ª–µ–π –≤ –¥–Ω—è—Ö (–æ—Ç –º–æ–º–µ–Ω—Ç–∞ –∑–∞–ø—É—Å–∫–∞ —Å–∫—Ä–∏–ø—Ç–∞)

CONFIG_FILE = 'config.json' # –§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
PROFILE_CLEANING_RULES_DEFAULT = [ # –ü—Ä–∞–≤–∏–ª–∞ –æ—á–∏—Å—Ç–∫–∏ –ø—Ä–æ—Ñ–∏–ª–µ–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    '%0A', '%250A', '%0D', 'amp;', 'ÔøΩ', 'fp=(firefox|safari|edge|360|qq|ios|android|randomized|random)'
]
PROFILE_CLEANING_RULES = PROFILE_CLEANING_RULES_DEFAULT

# --- –≠–º–æ–¥–∑–∏ –¥–ª—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ ---
VLESS_EMOJI = "üå†"
HY2_EMOJI = "‚ö°"
TUIC_EMOJI = "üöÄ"
TROJAN_EMOJI = "üõ°Ô∏è"
# --- –ö–æ–Ω–µ—Ü –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö –∫–æ–Ω—Å—Ç–∞–Ω—Ç ---

if not os.path.exists('config-tg.txt'):
    with open('config-tg.txt', 'w'): pass

def json_load(path: str) -> Optional[dict]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç JSON —Ñ–∞–π–ª –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—à–∏–±–∫–∏.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        dict –∏–ª–∏ list –∏–ª–∏ None: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ JSON —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ —É—Å–ø–µ—à–Ω–∞.
                                None, –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è.
                                –õ–æ–≥–≥–∏—Ä—É–µ—Ç –æ—à–∏–±–∫–∏.
    """
    if not os.path.exists(path):
        logging.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
        return None

    try:
        with open(path, 'r', encoding="utf-8") as file:
            data = json.load(file)
            if not isinstance(data, (dict, list)):
                logging.error(f"–§–∞–π–ª {path} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç JSON –æ–±—ä–µ–∫—Ç –∏–ª–∏ –º–∞—Å—Å–∏–≤. –í–æ–∑–≤—Ä–∞—â–∞–µ–º None.")
                return None
            return data
    except json.JSONDecodeError as e:
        logging.error(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON –≤ —Ñ–∞–π–ª–µ: {path} - {e}. –í–æ–∑–≤—Ä–∞—â–∞–µ–º None.")
        return None

def json_save(data: dict, path: str, indent: int = 4, backup: bool = True) -> bool:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ JSON —Ñ–∞–π–ª —Å –∞—Ç–æ–º–∞—Ä–Ω—ã–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–º –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""
    try:
        if backup and os.path.exists(path):
            backup_path = path + '.bak'
            shutil.copy2(path, backup_path) # copy2 —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ

        with tempfile.NamedTemporaryFile(mode='w', encoding='utf-8', delete=False) as tmp_file:
            json.dump(data, tmp_file, ensure_ascii=False, indent=indent)
        temp_filepath = tmp_file.name
        os.replace(temp_filepath, path) # –ê—Ç–æ–º–∞—Ä–Ω–æ–µ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –≤ —Ü–µ–ª–µ–≤–æ–π —Ñ–∞–π–ª
        return True
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ JSON –≤ —Ñ–∞–π–ª {path}: {e}")
        return False

def filter_out_substrings(string_list: List[str]) -> List[str]:
    """
    –£–¥–∞–ª—è–µ—Ç –ø–æ–¥—Å—Ç—Ä–æ–∫–∏ –∏–∑ —Å–ø–∏—Å–∫–∞ —Å—Ç—Ä–æ–∫.
    –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–æ –∏–∑ substring_del –¥–ª—è –±–æ–ª—å—à–µ–π –ø–æ–Ω—è—Ç–Ω–æ—Å—Ç–∏.
    """
    string_list.sort(key=len)
    strings_to_remove = set()
    for i in range(len(string_list)):
        for j in range(i + 1, len(string_list)):
            if string_list[i] in string_list[j]:
                strings_to_remove.add(string_list[i])
                break
    return [s for s in string_list if s not in strings_to_remove]

def calculate_profile_score(profile: str) -> int:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç —Å–∫–æ—Ä –ø—Ä–æ—Ñ–∏–ª—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.
    """
    protocol = profile.split("://")[0]
    if protocol not in ALLOWED_PROTOCOLS:
        return 0

    score = 0
    try:
        params_str = profile.split("://")[1]
        if "@" in params_str:
            params_str = params_str.split("@")[1]
        if "#" in params_str:
            params_str = params_str.split("#")[0]

        params = urllib_parse.parse_qs(params_str)

        def add_tls_score():
            nonlocal score
            if params.get("security", [""])[0] == "tls":
                score += PROFILE_SCORE_WEIGHTS.get("security", 0)
                score += PROFILE_SCORE_WEIGHTS.get("sni", 0) if "sni" in params else 0
                score += PROFILE_SCORE_WEIGHTS.get("alpn", 0) if "alpn" in params else 0

        if protocol == "vless":
            add_tls_score()
            score += PROFILE_SCORE_WEIGHTS.get("flow", 0) if "flow" in params else 0
            score += PROFILE_SCORE_WEIGHTS.get("headerType", 0) if "headerType" in params else 0
            score += PROFILE_SCORE_WEIGHTS.get("path", 0) if "path" in params else 0

        elif protocol == "hy2":
            add_tls_score()
            score += PROFILE_SCORE_WEIGHTS.get("obfs", 0) if "obfs" in params else 0

        elif protocol == "tuic":
            score += PROFILE_SCORE_WEIGHTS.get("alpn", 0) if "alpn" in params else 0
            score += PROFILE_SCORE_WEIGHTS.get("mport", 0) if "mport" in params else 0

        elif protocol == "trojan":
            add_tls_score()
            score += PROFILE_SCORE_WEIGHTS.get("obfs", 0) if "obfs" in params else 0

        base_params_count = len(profile.split("://")[1].split("@")[0].split(":"))
        score += base_params_count

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —Å–∫–æ—Ä–∞ –ø—Ä–æ—Ñ–∏–ª—è '{profile}': {e}")
        return 0

async def fetch_channel_page_async(session: aiohttp.ClientSession, channel_url: str, attempt: int) -> Optional[str]:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–∞–Ω–∞–ª–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ –∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏."""
    for attempt_num in range(attempt, 3): # –£–≤–µ–ª–∏—á–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –¥–æ 3 –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
        try:
            async with session.get(f'https://t.me/s/{channel_url}', timeout=REQUEST_TIMEOUT_AIOHTTP, ssl=False) as response: # ssl=False –¥–ª—è –æ–±—Ö–æ–¥–∞ InsecureRequestWarning
                response.raise_for_status()
                return await response.text()
        except aiohttp.ClientError as e: # –õ–æ–≤–∏–º –±–æ–ª–µ–µ –æ–±—â–∏–µ –æ—à–∏–±–∫–∏ aiohttp
            log_message = f"–û—à–∏–±–∫–∞ aiohttp –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ {channel_url}: {e}, –ø–æ–ø—ã—Ç–∫–∞ {attempt_num + 1}/3"
            if attempt_num < 2:
                delay = (2**attempt_num) + random.random() # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ + –¥–∂–∏—Ç—Ç–µ—Ä
                log_message += f". –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ {delay:.2f} —Å–µ–∫—É–Ω–¥."
                await asyncio.sleep(delay)
            logging.warning(log_message)
            if attempt_num >= 2:
                logging.error(f"–ü—Ä–µ–≤—ã—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ (3) –¥–ª—è {channel_url} –∏–∑-–∑–∞ –æ—à–∏–±–æ–∫ –∑–∞–ø—Ä–æ—Å–∞ aiohttp.")
                return None # –í–æ–∑–≤—Ä–∞—â–∞–µ–º None, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É
        except asyncio.TimeoutError:
            log_message = f"–¢–∞–π–º–∞—É—Ç aiohttp –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ {channel_url}, –ø–æ–ø—ã—Ç–∫–∞ {attempt_num + 1}/3"
            if attempt_num < 2:
                delay = (2**attempt_num) + random.random() # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ + –¥–∂–∏—Ç—Ç–µ—Ä
                log_message += f". –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ {delay:.2f} —Å–µ–∫—É–Ω–¥."
                await asyncio.sleep(delay)
            logging.warning(log_message)
            if attempt_num >= 2:
                logging.error(f"–ü—Ä–µ–≤—ã—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ (3) –¥–ª—è {channel_url} –∏–∑-–∑–∞ —Ç–∞–π–º–∞—É—Ç–æ–≤ aiohttp.")
                return None # –í–æ–∑–≤—Ä–∞—â–∞–µ–º None, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É
    return None # –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ—É–¥–∞—á–Ω—ã

async def parse_profiles_from_page_async(html_page: str, channel_url: str, allowed_protocols: Set[str], profile_score_func) -> List[Dict]:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–∞—Ä—Å–∏—Ç –ø—Ä–æ—Ñ–∏–ª–∏ –∏–∑ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã."""
    channel_profiles = []
    soup = BeautifulSoup(html_page, 'html.parser')
    message_blocks = soup.find_all('div', class_='tgme_widget_message')
    htmltag_pattern = re.compile(r'<.*?>')

    for message_block in message_blocks:
        code_tags = message_block.find_all(class_='tgme_widget_message_text')
        time_tag = message_block.find('time', class_='datetime')
        message_datetime = None
        if time_tag and 'datetime' in time_tag.attrs:
            try:
                message_datetime = datetime.fromisoformat(time_tag['datetime']).replace(tzinfo=timezone.utc)
            except ValueError:
                logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∞—Ç—É –∏–∑ time tag –¥–ª—è –∫–∞–Ω–∞–ª–∞ {channel_url}: {time_tag['datetime']}")

        for code_tag in code_tags:
            code_content_lines = str(code_tag).split('<br/>')
            for line in code_content_lines:
                cleaned_content = re.sub(htmltag_pattern, '', line).strip()
                for protocol in allowed_protocols:
                    if f"{protocol}://" in cleaned_content:
                        profile_link = cleaned_content
                        score = profile_score_func(profile_link) # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Å–∫–æ—Ä–∏–Ω–≥–∞
                        channel_profiles.append({'profile': profile_link, 'score': score, 'date': message_datetime})
    return channel_profiles

async def process_channel_async(channel_url: str, parsed_profiles: List[Dict], thread_semaphore: asyncio.Semaphore, telegram_channel_names: List[str], channels_parsed_count: int, channels_with_profiles: Set[str], channel_failure_counts: Dict[str, int], channels_to_remove: List[str], no_more_pages_counts: Dict[str, int], allowed_protocols: Set[str], profile_score_func) -> None:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —Ç–µ–ª–µ–≥—Ä–∞–º –∫–∞–Ω–∞–ª –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª–µ–π."""
    failed_check = False # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π failed_check
    channel_removed_in_run = False # –§–ª–∞–≥, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥–≤–æ–π–Ω–æ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ channels_to_remove –∑–∞ –æ–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥
    async with thread_semaphore: # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Å–µ–º–∞—Ñ–æ—Ä
        try:
            html_pages = []
            current_url = channel_url
            channel_profiles = []
            god_tg_name = False
            pattern_datbef = re.compile(r'(?:data-before=")(\d*)')
            no_more_pages_in_run = False


            async with aiohttp.ClientSession() as session: # –°–æ–∑–¥–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Å–µ—Å—Å–∏—é aiohttp
                for attempt in range(2): # –û—Å—Ç–∞–≤–ª—è–µ–º 2 –ø–æ–ø—ã—Ç–∫–∏ –Ω–∞ –∑–∞–≥—Ä—É–∑–∫—É —Å—Ç—Ä–∞–Ω–∏—Ü
                    while True:
                        html_page = await fetch_channel_page_async(session, current_url, attempt + 1) # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                        if html_page:
                            html_pages.append(html_page)
                            last_datbef = re.findall(pattern_datbef, html_page)
                            if not last_datbef:
                                logging.info(f"–ë–æ–ª—å—à–µ —Å—Ç—Ä–∞–Ω–∏—Ü –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –¥–ª—è {channel_url}")
                                no_more_pages_in_run = True
                                break
                            current_url = f'{channel_url}?before={last_datbef[0]}'
                            break
                        else:
                            failed_check = True # –ï—Å–ª–∏ fetch_channel_page_async –≤–µ—Ä–Ω—É–ª None, —Å—á–∏—Ç–∞–µ–º –Ω–µ—É–¥–∞—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π
                            break # –í—ã—Ö–æ–¥–∏–º –∏–∑ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ —Ü–∏–∫–ª–∞ while True, —Ç–∞–∫ –∫–∞–∫ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É

                    if failed_check: # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –≤—ã—Ö–æ–¥–∏–º –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ —Ü–∏–∫–ª–∞ for attempt
                        break

                if not html_pages:
                    logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –∫–∞–Ω–∞–ª–∞ {channel_url} –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—ã—Ç–æ–∫. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–∞–Ω–∞–ª.")
                    failed_check = True
                else:
                    failed_check = False

                channel_index = telegram_channel_names.index(channel_url) + 1
                logging.info(f'{channel_index} –∏–∑ {channels_parsed_count} - {channel_url}')

                if not failed_check:
                    for page in html_pages:
                        profiles_on_page = await parse_profiles_from_page_async(page, channel_url, allowed_protocols, profile_score_func) # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ—Ñ–∏–ª–µ–π
                        channel_profiles.extend(profiles_on_page)

            if channel_profiles:
                channels_with_profiles.add(channel_url)
                channel_failure_counts[channel_url] = 0  # –°–±—Ä–æ—Å —Å—á–µ—Ç—á–∏–∫–∞ –Ω–µ—É–¥–∞—á, –µ—Å–ª–∏ –ø—Ä–æ—Ñ–∏–ª–∏ –Ω–∞–π–¥–µ–Ω—ã
                no_more_pages_counts[channel_url] = 0  # –°–±—Ä–æ—Å —Å—á–µ—Ç—á–∏–∫–∞ "–ë–æ–ª—å—à–µ —Å—Ç—Ä–∞–Ω–∏—Ü –Ω–µ –Ω–∞–π–¥–µ–Ω–æ", –µ—Å–ª–∏ –ø—Ä–æ—Ñ–∏–ª–∏ –Ω–∞–π–¥–µ–Ω—ã
                god_tg_name = True # –ü—Ä–æ—Ñ–∏–ª–∏ –Ω–∞–π–¥–µ–Ω—ã
            else:
                god_tg_name = False # –ü—Ä–æ—Ñ–∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã

            if god_tg_name:
                pass # –£–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤—ã—à–µ
            else:
                if channel_url in channel_failure_counts:
                    channel_failure_counts[channel_url] += 1
                else:
                    channel_failure_counts[channel_url] = 1

                if channel_failure_counts[channel_url] >= MAX_FAILED_CHECKS and channel_url not in channels_to_remove:
                    channels_to_remove.append(channel_url)
                    channel_removed_in_run = True
                    logging.info(f"–ö–∞–Ω–∞–ª '{channel_url}' –±—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω –∏–∑ —Å–ø–∏—Å–∫–∞ –∑–∞ {MAX_FAILED_CHECKS} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –Ω–µ—É–¥–∞—á–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫.")
                elif not god_tg_name and not channel_removed_in_run:
                    logging.info(f"–ü—Ä–æ—Ñ–∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –∫–∞–Ω–∞–ª–µ {channel_url}. –ù–µ—É–¥–∞—á–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –ø–æ–¥—Ä—è–¥: {channel_failure_counts[channel_url]}/{MAX_FAILED_CHECKS}.")
                elif channel_removed_in_run:
                    pass

            if no_more_pages_in_run:
                if channel_url in no_more_pages_counts:
                    no_more_pages_counts[channel_url] += 1
                else:
                    no_more_pages_counts[channel_url] = 1

                if no_more_pages_counts[channel_url] >= MAX_NO_MORE_PAGES_COUNT and channel_url not in channels_to_remove:
                    channels_to_remove.append(channel_url)
                    channel_removed_in_run = True
                    logging.info(f"–ö–∞–Ω–∞–ª '{channel_url}' –±—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω –∏–∑ —Å–ø–∏—Å–∫–∞ –∑–∞ {MAX_NO_MORE_PAGES_COUNT} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π '–ë–æ–ª—å—à–µ —Å—Ç—Ä–∞–Ω–∏—Ü –Ω–µ –Ω–∞–π–¥–µ–Ω–æ'. –ö–∞–Ω–∞–ª –≤–µ—Ä–æ—è—Ç–Ω–æ –Ω–µ–∞–∫—Ç–∏–≤–µ–Ω.")
                elif no_more_pages_in_run and not channel_removed_in_run:
                    logging.info(f"–î–ª—è –∫–∞–Ω–∞–ª–∞ '{channel_url}' –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ '–ë–æ–ª—å—à–µ —Å—Ç—Ä–∞–Ω–∏—Ü –Ω–µ –Ω–∞–π–¥–µ–Ω–æ'. –°–æ–æ–±—â–µ–Ω–∏–π –ø–æ–¥—Ä—è–¥: {no_more_pages_counts[channel_url]}/{MAX_NO_MORE_PAGES_COUNT}.")
                elif channel_removed_in_run:
                    pass

            parsed_profiles.extend(channel_profiles)

        except Exception as channel_exception:
            logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–∞–Ω–∞–ª–∞ {channel_url}: {channel_exception}")

def clean_profile(profile_string: str) -> str:
    """–û—á–∏—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –ø—Ä–æ—Ñ–∏–ª—è –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–∞–≤–∏–ª–∞ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."""
    part = profile_string
    for rule in PROFILE_CLEANING_RULES:
        part = re.sub(rule, '', part, flags=re.IGNORECASE) # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–∞–∂–¥–æ–µ –ø—Ä–∞–≤–∏–ª–æ –∏–∑ —Å–ø–∏—Å–∫–∞
    part = urllib_parse.unquote(urllib_parse.unquote(part)).strip()
    part = re.sub(' ', '', part)
    part = re.sub(r'\x00', '', part)
    part = re.sub(r'\x01', '', part)
    return part

async def process_parsed_profiles_async(parsed_profiles_list: List[Dict]) -> List[Dict]:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π: –æ—á–∏—Å—Ç–∫–∞, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞–º,
    —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏ –ø–æ–¥—Å—Ç—Ä–æ–∫, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Å–≤–µ–∂–µ—Å—Ç–∏, –∏—Ç–æ–≥–æ–≤–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞.
    """
    processed_profiles = []

    for item in parsed_profiles_list:
        cleaned_profile_string = clean_profile(item['profile'])
        protocol = ""
        profile_to_add = None

        params_str = cleaned_profile_string.split("://")[1]
        if "@" in params_str:
            params_str = params_str.split("@")[1]
        if "#" in params_str:
            params_str = params_str.split("#")[0]
        params = urllib_parse.parse_qs(params_str)

        security_info = "NoTLS"  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        if params.get("security", [""])[0] == "tls":
            security_info = "TLS"

        if "vless://" in cleaned_profile_string:
            protocol = "vless"
            part = f'vless://{cleaned_profile_string.split("vless://")[1]}'
            if "flow=xtls-rprx-direct" not in part and "@" in part and ":" in part[8:]:
                profile_to_add = {
                    'profile': part.strip(),
                    'score': item['score'],
                    'date': item['date'],
                    'profile_name': f"{VLESS_EMOJI}{protocol.upper()} ({security_info})"
                }
        elif "hy2://" in cleaned_profile_string:
            protocol = "hy2"
            part = f'hy2://{cleaned_profile_string.split("hy2://")[1]}'
            if "@" in part and ":" in part[6:]:
                profile_to_add = {
                    'profile': part.strip(),
                    'score': item['score'],
                    'date': item['date'],
                    'profile_name': f"{HY2_EMOJI}{protocol.upper()} ({security_info})"
                }
        elif "tuic://" in cleaned_profile_string:
            protocol = "tuic"
            part = f'tuic://{cleaned_profile_string.split("tuic://")[1]}'
            profile_to_add = {
                'profile': part.strip(),
                'score': item['score'],
                'date': item['date'],
                'profile_name': f"{TUIC_EMOJI}{protocol.upper()} (QUIC)"
            }
        elif "trojan://" in cleaned_profile_string:
            protocol = "trojan"
            part = f'trojan://{cleaned_profile_string.split("trojan://")[1]}'
            if "@" in part and ":" in part[9:]:
                profile_to_add = {
                    'profile': part.strip(),
                    'score': item['score'],
                    'date': item['date'],
                    'profile_name': f"{TROJAN_EMOJI}{protocol.upper()} ({security_info})"
                }
        if profile_to_add:
            processed_profiles.append(profile_to_add)

    logging.info(f'–ü—ã—Ç–∞–µ–º—Å—è —É–¥–∞–ª–∏—Ç—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏, –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ —Å–≤–µ–∂–µ—Å—Ç–∏...')

    unique_profiles_scored = []
    seen_profiles = set()
    for profile_data in processed_profiles:
        profile = profile_data['profile']
        if profile not in seen_profiles and (len(profile) > 13) and (("‚Ä¶" in profile and "#" in profile) or ("‚Ä¶" not in profile)):
            unique_profiles_scored.append(profile_data)
            seen_profiles.add(profile)

    new_processed_profiles_scored = []
    for profile_data in unique_profiles_scored:
        x = profile_data['profile']
        x = re.sub(r'‚Ä¶¬ª$|‚Ä¶$|¬ª$|%$|`$', '', x).strip()
        if x[-2:-1] == '%':
            x = x[:-2]
        new_processed_profiles_scored.append({
            'profile': x.strip(),
            'score': profile_data['score'],
            'date': profile_data['date'],
            'profile_name': profile_data['profile_name']
        })

    processed_profiles_scored = new_processed_profiles_scored
    processed_profiles_strings = [item['profile'] for item in processed_profiles_scored]
    processed_profiles_strings = filter_out_substrings(processed_profiles_strings) # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é

    final_profiles_scored = []
    profile_strings_set = set(processed_profiles_strings)
    for profile_data in processed_profiles_scored:
        if profile_data['profile'] in profile_strings_set:
            final_profiles_scored.append(profile_data)
            profile_strings_set.remove(profile_data['profile'])

    # --- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Å–≤–µ–∂–µ—Å—Ç–∏ ---
    fresh_profiles_scored = []
    now = datetime.now(tz=timezone.utc)
    for profile_data in final_profiles_scored:
        if 'date' in profile_data and isinstance(profile_data['date'], datetime):
            time_difference = now - profile_data['date']
            if time_difference <= timedelta(days=PROFILE_FRESHNESS_DAYS):
                fresh_profiles_scored.append(profile_data)
            else:
                logging.info(f"–£–¥–∞–ª–µ–Ω —É—Å—Ç–∞—Ä–µ–≤—à–∏–π –ø—Ä–æ—Ñ–∏–ª—å (—Å—Ç–∞—Ä—à–µ {PROFILE_FRESHNESS_DAYS} –¥–Ω–µ–π): –¥–∞—Ç–∞ {profile_data['date'].strftime('%Y-%m-%d %H:%M:%S UTC')}, –ø—Ä–æ—Ñ–∏–ª—å: {profile_data['profile'][:100]}...")
        else:
            fresh_profiles_scored.append(profile_data)

    final_profiles_scored = fresh_profiles_scored
    logging.info(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ —Å–≤–µ–∂–µ—Å—Ç–∏ –æ—Å—Ç–∞–ª–æ—Å—å {len(final_profiles_scored)} –ø—Ä–æ—Ñ–∏–ª–µ–π.")

    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞: –µ—Å–ª–∏ score —Ä–∞–≤–µ–Ω None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 0
    final_profiles_scored.sort(key=lambda item: item.get('score') or 0, reverse=True)
    return final_profiles_scored

class ChannelHistoryManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –∫–∞–Ω–∞–ª–æ–≤ (–Ω–µ—É–¥–∞—á –∏ '–ë–æ–ª—å—à–µ —Å—Ç—Ä–∞–Ω–∏—Ü –Ω–µ –Ω–∞–π–¥–µ–Ω–æ')."""
    def __init__(self, failure_file: str = FAILURE_HISTORY_FILE, no_more_pages_file: str = NO_MORE_PAGES_HISTORY_FILE):
        self.failure_file = failure_file
        self.no_more_pages_file = no_more_pages_file

    def _load_json_history(self, filepath: str) -> Dict:
        if not os.path.exists(filepath):
            logging.warning(f"–§–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏ '{filepath}' –Ω–µ –Ω–∞–π–¥–µ–Ω –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ. –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª.")
            if not json_save({}, filepath): # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∏ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞
                logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏: {filepath}")
                return {} # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ —Å–æ–∑–¥–∞–Ω–∏—è
            return {}
        history = json_load(filepath)
        return history if history else {}

    def _save_json_history(self, history: Dict, filepath: str) -> bool:
        return json_save(history, filepath)

    def load_failure_history(self) -> Dict:
        return self._load_json_history(self.failure_file)

    def save_failure_history(self, history: Dict) -> bool:
        return self._save_json_history(history, self.failure_file)

    def load_no_more_pages_history(self) -> Dict:
        return self._load_json_history(self.no_more_pages_file)

    def save_no_more_pages_history(self, history: Dict) -> bool:
        return self._save_json_history(history, self.no_more_pages_file)

async def load_channels_async(channels_file: str = 'telegram_channels.json') -> List[str]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ –∏–∑ JSON —Ñ–∞–π–ª–∞."""
    telegram_channel_names_original = json_load(channels_file)
    if telegram_channel_names_original is None:
        logging.critical(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ –∏–∑ {channels_file}. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
        exit(1)
    telegram_channel_names_original[:] = [x for x in telegram_channel_names_original if len(x) >= 5]
    return list(set(telegram_channel_names_original))

async def run_parsing_async(telegram_channel_names_to_parse: List[str], channel_history_manager: ChannelHistoryManager) -> tuple[List[Dict], Set[str], List[str], Dict, Dict]:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∫–∞–Ω–∞–ª–æ–≤."""
    channels_parsed_count = len(telegram_channel_names_to_parse)
    logging.info(f'–ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ {channels_parsed_count} —Ç–µ–ª–µ–≥—Ä–∞–º –∫–∞–Ω–∞–ª–æ–≤...')

    channel_failure_counts = channel_history_manager.load_failure_history()
    no_more_pages_counts = channel_history_manager.load_no_more_pages_history()
    channels_to_remove = []
    thread_semaphore = asyncio.Semaphore(MAX_THREADS_PARSING)
    parsed_profiles = []
    channels_with_profiles = set()

    tasks = [] # –°–ø–∏—Å–æ–∫ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
    for channel_name in telegram_channel_names_to_parse:
        task = asyncio.create_task(
            process_channel_async(channel_name, parsed_profiles, thread_semaphore, telegram_channel_names_to_parse,
                                channels_parsed_count, channels_with_profiles, channel_failure_counts,
                                channels_to_remove, no_more_pages_counts, ALLOWED_PROTOCOLS, calculate_profile_score)
        )
        tasks.append(task)

    await asyncio.gather(*tasks) # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –∏ –∂–¥–µ–º –∏—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è

    return parsed_profiles, channels_with_profiles, channels_to_remove, channel_failure_counts, no_more_pages_counts

def save_results(final_profiles_scored: List[Dict], profiles_to_save: List[Dict], channels_to_remove: List[str], telegram_channel_names_original: List[str], channel_history_manager: ChannelHistoryManager, channel_failure_counts: Dict, no_more_pages_counts: Dict) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–∞—Ä—Å–∏–Ω–≥–∞: –ø—Ä–æ—Ñ–∏–ª–∏, –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤, –∏—Å—Ç–æ—Ä–∏—é."""
    num_profiles_to_save = min(max(len(final_profiles_scored), MIN_PROFILES_TO_DOWNLOAD), MAX_PROFILES_TO_DOWNLOAD)
    profiles_to_save = final_profiles_scored[:num_profiles_to_save]

    with open("config-tg.txt", "w", encoding="utf-8") as file:
        for profile_data in profiles_to_save:
            file.write(f"{profile_data['profile'].encode('utf-8').decode('utf-8')} {profile_data['profile_name']}\n")

    if channels_to_remove:
        logging.info(f"–£–¥–∞–ª—è–µ–º –∫–∞–Ω–∞–ª—ã: {channels_to_remove}")
        telegram_channel_names_updated = [chan for chan in telegram_channel_names_original if chan not in channels_to_remove]
        if telegram_channel_names_updated != telegram_channel_names_original:
            json_save(telegram_channel_names_updated, 'telegram_channels.json')
            logging.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ telegram_channels.json. –£–¥–∞–ª–µ–Ω–æ –∫–∞–Ω–∞–ª–æ–≤: {len(channels_to_remove)}.")
        else:
            logging.info("–°–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ –≤ telegram_channels.json –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è (—É–¥–∞–ª–µ–Ω–∏–µ –Ω–µ –ø–æ—Ç—Ä–µ–±–æ–≤–∞–ª–æ—Å—å).")
    else:
        logging.info("–ù–µ—Ç –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è.")

    channel_history_manager.save_failure_history(channel_failure_counts)
    channel_history_manager.save_no_more_pages_history(no_more_pages_counts)

def log_statistics(start_time: datetime, initial_channels_count: int, channels_parsed_count: int, parsed_profiles: List[Dict], final_profiles_scored: List[Dict], profiles_to_save: List[Dict], channels_with_profiles: Set[str], channels_to_remove: List[str]) -> None:
    """–õ–æ–≥–∏—Ä—É–µ—Ç –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–∞—Ä—Å–∏–Ω–≥–∞."""
    end_time = datetime.now()
    total_time = end_time - start_time

    logging.info(f'{"-"*40}')
    logging.info(f'{"--- –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ---":^40}')
    logging.info(f'{"-"*40}')
    logging.info(f'–û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {str(total_time).split(".")[0]}')
    logging.info(f'–ù–∞—á–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤ –≤ telegram_channels.json: {initial_channels_count}')
    logging.info(f'–ö–∞–Ω–∞–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {channels_parsed_count}')
    logging.info(f'–ö–∞–Ω–∞–ª–æ–≤, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –Ω–∞–π–¥–µ–Ω—ã –ø—Ä–æ—Ñ–∏–ª–∏: {len(channels_with_profiles)}')
    logging.info(f'–ü—Ä–æ—Ñ–µ–ª–µ–π –Ω–∞–π–¥–µ–Ω–æ –≤–æ –≤—Ä–µ–º—è –ø–∞—Ä—Å–∏–Ω–≥–∞ (–¥–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏): {len(parsed_profiles)}')
    logging.info(f'–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(final_profiles_scored)}')
    logging.info(f'–ü—Ä–æ—Ñ–µ–ª–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ config-tg.txt: {len(profiles_to_save)}')
    if channels_to_remove:
        logging.info(f'–ö–∞–Ω–∞–ª–æ–≤ —É–¥–∞–ª–µ–Ω–æ –∏–∑ —Å–ø–∏—Å–∫–∞: {len(channels_to_remove)}')
    else:
        logging.info(f'–ö–∞–Ω–∞–ª–æ–≤ —É–¥–∞–ª–µ–Ω–æ –∏–∑ —Å–ø–∏—Å–∫–∞: 0')
    logging.info(f'{"-"*40}')
    logging.info('–ó–∞–≤–µ—Ä—à–µ–Ω–æ!')

async def main_async():
    """–ì–ª–∞–≤–Ω–∞—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ—Ñ–∏–ª–µ–π."""
    logging.info(f'–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ {CONFIG_FILE}...')
    config_data = json_load(CONFIG_FILE)
    if config_data:
        global PROFILE_SCORE_WEIGHTS, PROFILE_CLEANING_RULES, PROFILE_FRESHNESS_DAYS, MAX_FAILED_CHECKS, MAX_NO_MORE_PAGES_COUNT, MAX_THREADS_PARSING, REQUEST_TIMEOUT_AIOHTTP, MIN_PROFILES_TO_DOWNLOAD, MAX_PROFILES_TO_DOWNLOAD
        PROFILE_SCORE_WEIGHTS = config_data.get('profile_score_weights', PROFILE_SCORE_WEIGHTS)
        PROFILE_CLEANING_RULES = config_data.get('profile_cleaning_rules', PROFILE_CLEANING_RULES_DEFAULT)
        PROFILE_FRESHNESS_DAYS = config_data.get('profile_freshness_days', PROFILE_FRESHNESS_DAYS)
        MAX_FAILED_CHECKS = config_data.get('max_failed_checks', MAX_FAILED_CHECKS)
        MAX_NO_MORE_PAGES_COUNT = config_data.get('max_no_more_pages_count', MAX_NO_MORE_PAGES_COUNT)
        MAX_THREADS_PARSING = config_data.get('max_threads_parsing', MAX_THREADS_PARSING)
        REQUEST_TIMEOUT_AIOHTTP = config_data.get('request_timeout_aiohttp', REQUEST_TIMEOUT_AIOHTTP)
        MIN_PROFILES_TO_DOWNLOAD = config_data.get('min_profiles_to_download', MIN_PROFILES_TO_DOWNLOAD)
        MAX_PROFILES_TO_DOWNLOAD = config_data.get('max_profiles_to_download', MAX_PROFILES_TO_DOWNLOAD)
        logging.info(f'–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞.')
    else:
        logging.warning(f'–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ {CONFIG_FILE}. –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.')

    start_time = datetime.now()
    telegram_channel_names_original = await load_channels_async()
    telegram_channel_names_to_parse = list(telegram_channel_names_original) # –ö–æ–ø–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –¥–ª—è –∏—Ç–µ—Ä–∞—Ü–∏–π
    initial_channels_count = len(telegram_channel_names_original)
    logging.info(f'–ù–∞—á–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤ –≤ telegram_channels.json: {initial_channels_count}')

    channel_history_manager = ChannelHistoryManager()
    logging.info(f'–ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥...')
    parsed_profiles, channels_with_profiles, channels_to_remove, channel_failure_counts, no_more_pages_counts = await run_parsing_async(telegram_channel_names_to_parse, channel_history_manager)
    logging.info(f'–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é —Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥–æ–≤...')

    final_profiles_scored = await process_parsed_profiles_async(parsed_profiles)
    profiles_to_save = final_profiles_scored[:min(max(len(final_profiles_scored), MIN_PROFILES_TO_DOWNLOAD), MAX_PROFILES_TO_DOWNLOAD)]
    save_results(final_profiles_scored, profiles_to_save, channels_to_remove, telegram_channel_names_original, channel_history_manager, channel_failure_counts, no_more_pages_counts)
    log_statistics(start_time, initial_channels_count, len(telegram_channel_names_to_parse), parsed_profiles, final_profiles_scored, profiles_to_save, channels_with_profiles, channels_to_remove)

if __name__ == "__main__":
    asyncio.run(main_async())
